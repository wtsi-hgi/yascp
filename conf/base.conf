/*
========================================================================================
    nf-core/yascp Nextflow base config file
========================================================================================
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/

params{
    input = 'cellbender' //# cellbender|cellranger
    rsync_to_web_file = "${launchDir}/yascp/bin/rsync_to_web.sh"
    profile = 'normal_run'
    
    atac=false
    input_data_table = "${projectDir}/assets/fake_fileinput.tsv"
    bam_pileup_per_donor = false
    concordance_calculations = false
    gather_and_calculate_stats = true
    //# estimate_and_provide_informative_snps_for_deconvolution=false
    perform_concordance_calculations = false
    filter_outliers = true
    remap_celltypes = true
    cellbender_v = '0.2.0' // # 0.2.0 | 0.3.1
    //# These are default parameters that can be overwriten to run in a different mode.
    //# Here we have listed the default parameters when running without any extrainput.
    tmpdir = "${launchDir}/work"
    cohorts_to_drop_from_GT_Relatednes_check=''
    provide_within_pool_donor_specific_sites_for_pilup = false
    hard_filters_file = "no_file__file_sample_qc" //# This may point to the sample_qc.yml input which will apply hard filters to the merged cells.
    hard_filters_drop = false //#This indicates whether we want to drop the cells that fail hard filters of just flag them
    add_snps_to_pile_up_based_on_genotypes_provided = false // #whether we want to add informative snp to pile up in bam to enhance deconvolutions.
    bcf_viewfilters = ""
    encrypt = false
    write_h5 = true
    remove_work_dir = false
    cellbender_location="${launchDir}/results"
    skip_handover = false
    RUN='default'
    skip_qc=false
    skip_merge=false
    just_reports=false
    add_donor_metadata = false
    cellex_cluster_markers=false
    mem1= 12000
    copy_mode = "rellink"
    split_bam = false
    cluster_markers = false
    existing_cellsnp="${projectDir}/assets/existing_cellsnp"
    bridge_file="${projectDir}/assets/fake_file.fq"
    existing_vireo="${projectDir}/assets/existing_cellsnp"
    normalise_andata = true
    skip_preprocessing=false
    file__anndata_merged = ''
    gt_match_file="" // #We prvide this if we want to exclude a particular samples matched to a ceirtain GT cohortc from the adaptive qc
    gt_match_based_adaptive_qc_exclusion_pattern = '' // #We run the adaptive QC on these patterns independently regardless on assigned celltype.        
    file__cells_filtered = ''
    id_in='experiment_id'
    genotype_phenotype_mapping_file = genotype_phenotype_mapping_file2 =''
    extra_sample_metadata = ''
    use_phenotype_ids_for_gt_match = true //#if false this will keep the genotype ids, for this to be used have to set a genotype_phenotype_mapping_file to a path to csv where firs column contains genotype ids and second contains phenotype ids to replace these to.
    run_celltype_assignment = true
    cluster_validate_resolution_keras = true
    input_tables_column_delimiter = '\t'
    outdir= "${launchDir}/results"
    tracedir                   = "${params.outdir}/pipeline_info"
    do_deconvolution = true
    split_bam = false
    run_multiplet = true
    utilise_gpu = true
    split_ad_per_bach = true
    cellbender_resolution_to_use='0pt1'
    reference_assembly_fasta_dir = " /nfs/srpipe_references/downloaded_from_10X/refdata-gex-GRCh38-2020-A/fasta/"
    //# reference_assembly_fasta_dir = "https://yascp.cog.sanger.ac.uk/public/10x_reference_assembly"
    webtransfer = false
    project_name = 'Cardinal_pilots'
    run_with_genotype_input=false
    tmpdir = "${launchDir}/work"

    eQTL{
        eqtl_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/eqtl_26_10_2022.img'
        aggregation_collumn='Azimuth:predicted.celltype.l2'
        n_min_cells = '5' // #The number of cells for individual to use. 
        n_min_individ = '30' // #Do not select less than 25 since this may result in a permutation issue with tensorqtl
        aggregation_method = 'dMean,dSum'
    }
    just_overlapping_positions_for_study_merge=false

    citeseq = true
    citeseq_config{
        citeseq_labels = '"Hastag_.*,Another_Label"' //# These list hastag labels, these can be part of either antibody capture or in independent data modality. This works with regex. They can be ' ' or ',' seperated
    }

	genotype_input {
        subset_genotypes = false // # if activated this will use the IDs provided in the input.tsv to to perform the GT match against, otherwise it will match against full cohort.
        run_with_genotype_input= false // #Whether we are using genotypes in our runs.
        vireo_with_gt=false // #if activated this will run vireo with genotypes.
        subset_vireo_genotypes = true // # This is a switch that determines whether we want to provide full genotype file in the vireo as an input or subset it down to the expected donors. NOTE: you may want to provide already merged shards for this, otherwise pipeline will merge this for you.
        posterior_assignment = false // #if this is set to true, we will perform the genotype donor matching after the deconvolution is performed.
        tsv_donor_panel_vcfs = "" // #tlist of vcf/bcf inputs 1) Can be a single file 2) Can be multiple cohorts (in cases where we dont want to merge the genotypes together) 3) Can be sharded inputs (for example per chromosome)
        ZSCORE_THRESH = 3 //# Minimum z0 threshold required to call the gt assignment confident. 
        ZSCORE_DIST_THRESH = 3 //# Minimum bifference between z0 and z1 to call the assignment confident,
        genotype_correlation_threshold = 0.6 //# Threshod to be used to determine sample correlation and which samples are coming from same donor. 
    }

    cellsnp {
        run = true
        remove_workdir = false
        copy_mode = "rellink"
        vcf_candidate_snps = "https://yascp.cog.sanger.ac.uk/public/cellsnp/genome1K.phase3.SNP_AF5e2.chr1toX.hg38.vcf.gz"
        description = """// this list of candidate SNPs for cellSNP comes from link at https://github.com/single-cell-genetics/cellSNP
        // i.e., https://sourceforge.net/projects/cellsnp/files/SNPlist/genome1K.phase3.SNP_AF5e2.chr1toX.hg38.vcf.gz/download"""
        min_maf = "0.1"
        min_count = "20"
        p = "20"
    }

    vireo {
        run = true
        remove_workdir = false
        copy_mode = "rellink"
        run_gtmatch_aposteriori = true
        subsample_times=10
        rate=60
   }

    plot_donor_ncells {
        run = false
        remove_workdir = false
        copy_mode = "rellink"
        plotnine_dpi = "100"
    }

    souporcell {
        run = true
        use_raw_barcodes = false
        remove_workdir = false
        copy_mode = "rellink"
        reference_fasta = "https://yascp.cog.sanger.ac.uk/public/10x_reference_assembly/genome.fa"
     }


    plot_souporcell_vs_vireo {
        run = false
        remove_workdir = false
        copy_mode = "rellink"
    }

    cellsnp_recapture ='1'
    split_h5ad_per_donor {
        run = true
        remove_workdir = false
        copy_mode = "rellink"
        input_h5_genome_version = "GRCh38"
        print_modules_version = "True"
        plot_n_cells_per_vireo_donor = "True"
        write_donor_level_filtered_cells_h5 = "True"
        plotnine_dpi = "100"
        anndata_compression_level = "6"
    }


    ////////////
    //Containers
        // QC container //
        nf_scrna_qc_sif_container="https://yascp.cog.sanger.ac.uk/public/singularity_images/wtsihgi_nf_scrna_qc_6bb6af5-2021-12-23-3270149cf265.sif"
        nf_scrna_qc_azimuth_container="https://yascp.cog.sanger.ac.uk/public/singularity_images/wtsihgi_nf_scrna_qc_azimuth_d54db9b-2021-12-13-8dd0b7fce918.sif"
        azimuth_dsb_container="https://yascp.cog.sanger.ac.uk/public/singularity_images/azimuth_dsb_6_03_2024.sif"
        nf_scrna_qc_v3_container = "https://yascp.cog.sanger.ac.uk/public/singularity_images/nf_scrna_qc_v3.img"
        nf_qc_cluster_sccaf_container = "https://yascp.cog.sanger.ac.uk/public/singularity_images/nf_qc_cluster_sccaf_1.5.img"

        // Cellbender Containers
        nf_cellbender_container="https://yascp.cog.sanger.ac.uk/public/singularity_images/wtsihgi_nf_cellbender_container_3cc9983-2021-12-14-5e3143ef9e66.sif"
        nf_cellbender_container_032="https://yascp.cog.sanger.ac.uk/public/singularity_images/cellbender_28_02_2024.sif"
        
        // Deconvolution Containers
        scrna_deconvolution = "https://yascp.cog.sanger.ac.uk/public/singularity_images/mercury_scrna_deconvolution_62bd56a-2021-12-15-4d1ec9312485.sif"
        nf_yascp_celltypist = "https://yascp.cog.sanger.ac.uk/public/singularity_images/scrna_deconvolution_v3.img"

        // totalvi and bam processing containers
        total_vi_container = "https://yascp.cog.sanger.ac.uk/public/singularity_images/yascp_totalvi_v1.sif"
        nf_yascp_htstools_container = "https://yascp.cog.sanger.ac.uk/public/singularity_images/wtsihgi-nf_yascp_htstools-1.1.sif"
        bam_tool_processing_container = "https://yascp.cog.sanger.ac.uk/public/singularity_images/bam_tool_processing_05_04_2024.sif"
        
        // Cell type containers
        cell_classification_container ="https://yascp.cog.sanger.ac.uk/public/singularity_images/cell_classification.sif"
        souporcell_container ="https://yascp.cog.sanger.ac.uk/public/singularity_images/shub_wheaton5_souporcell_latest.img"
        
    ////////////
}

process {
    cache = 'lenient'

    cpus   = {  1    * task.attempt }
    memory = {  4.GB * task.attempt }
    time   = { 4.h  * task.attempt }
    containerOptions = " --cleanenv --containall -B "+params.tmpdir+":/tmp --env NUMBA_CACHE_DIR='"+params.tmpdir+"' --env MPLCONFIGDIR='"+params.tmpdir+"'"
    
    //# errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 5
    maxErrors     = '-1'
    errorStrategy = 'retry'
    // #Process-specific resource requirements
    // #NOTE - Please try and re-use the labels below as much as possible.
    // #       These labels are used and recognised by default in DSL2 files hosted on nf-core/modules.
    // #       If possible, it would be nice to keep the same label naming convention when
    // #       adding in your local modules too.
    // # The queues differ between institutions. So please chence them according to the times.

    withLabel:process_tiny {
      cpus = 1
      maxRetries    = 5
      memory = 2.GB
      time   = {  3.h   * task.attempt }
    }

    withLabel: gpu {
        cpus = 1
        maxForks=8
        errorStrategy = 'retry'
        memory = 20.GB 
        time   = { 12.h   * task.attempt }
    }

    withLabel:process_low {
        maxRetries    = 3
        cpus   = { 1     * task.attempt }
        memory = { 12.GB * task.attempt }
        time   = {  4.h   * task.attempt }
    }
    withLabel:medium_cpus {
        cpus   = {  1    * task.attempt }
        memory = { 36.GB * task.attempt }
        time   = {  12.h   * task.attempt }
    }

    withLabel:process_medium {
        cpus   = {  1     * task.attempt }
        memory = { 10.GB * 2* task.attempt }
        time   = {  12.h   * task.attempt }
        maxRetries    = 3
    }

    withLabel:process_medium_single_CPU {
        cpus   = { 1     * task.attempt }
    }
    withLabel:many_cores_small_mem {
        cpus   = {  20     * task.attempt }
        memory = { 20.GB * task.attempt }
        time   = { 12.h   * task.attempt }
    }

    withName: cellbender__rb__get_input_cells{
        memory = { 5.GB * task.attempt}
    }

    withName: SUBSET_GENOTYPE2{
        memory = { 200.MB * task.attempt}
        cpus   = { 1     * task.attempt }
        time   = { 1.h   * task.attempt }
    }

    withName: BBKNN{
        cpus   = 1
        //# memory = { 36.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }

    withName: JOIN_INFERED_EXPECTED_MERGE{
        cpus   = 1
        //# memory = { 36.GB * task.attempt }
        memory = { 4.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }

    withName: ENHANCE_STATS_GT_MATCH{
        cpus   = 1
        //# memory = { 36.GB * task.attempt }
        memory = { 2.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }
    
    withName: ASSIGN_DONOR_FROM_PANEL{
        cpus   = 1
        //# memory = { 36.GB * task.attempt }
        memory = { 2.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }

    withName: DOUBLET_DECON{
        cpus   = 1
        memory = { 36.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }
    withName: DOUBLET_FINDER{
        cpus   = 1
        memory = { 36.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }
    withName: PREPROCESS_GENOTYPES{
        cpus   = 1
        time   = 12.h
        maxRetries    = 3
    }

    withName: HARMONY{
        cpus   = 1
        //# memory = { 36.GB * task.attempt }
        time   = 12.h
        maxRetries    = 3
    }

    withName: CELLTYPE_FILE_MERGE{
        memory = { 7.GB * task.attempt}
        cpus   = 1
        time   = { 1.h   * task.attempt }
    }

    withLabel:process_high {
        cpus   = {  1    * task.attempt }
        memory = { 100.GB * task.attempt }
        time   = 48.h
    }
    withLabel:process_long {
        time   = 48.h
        memory = { 36.GB * task.attempt }
        cpus   = { 1     * task.attempt }
    }
    withLabel:process_extralong {
        time   = 78.h
    }
    withLabel:process_high_memory {
        memory = { 150.GB * task.attempt}
        maxRetries    = 5
        time   = { 12.h   * task.attempt }
    }
    withLabel:process_medium_memory {
        memory = { 30.GB * task.attempt }
    }
    withName: ASSESS_CALL_RATE{
        maxRetries    = 3
        memory = { 10.GB * task.attempt }
        errorStrategy = { task.attempt > 2 ? 'ignore' : 'retry' }
    }

}


def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

singularity {
  enabled = true
}
