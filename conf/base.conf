/*
========================================================================================
    nf-core/yascp Nextflow base config file
========================================================================================
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/

params{
    //# These are default parameters that can be overwriten to run in a different mode.
    //# Here we have listed the default parameters when running without any extrainput.
    bridge_file="${projectDir}/assets/fake_file.fq" // # Genotype phenotype bridging file. 
    input = 'cellbender' //# cellbender|cellranger
    
    just_overlapping_positions_for_study_merge=false // # If we have multiple studies in the runs, should we use only the overlapping positions in vcf files to prep the gt match table?

    cellbender_ignore_list = ['random_value_1234'] // #Which samples you would want to skip from cellbender processing. Sometimes a sample will be really bad and cause the pipeline to fail or retry. This allows to seemlesly skip this sample if it has caused issues.
    atac = false // # Is ths an ATAC dataset?
    bam_pileup_per_donor = false // # Whether you would like to pile up variants of each of the subset donor bams - this is usefull when there is just a single donor in a pool to identify the source. 
    concordance_calculations = false // # Whether to perform concordance calculations between the infered genotypes of donor cells vs the reference genotypes to inform which cells may not have a robus. assignemnts.

    cellbender_v='0.2.0' // # What version of cellbender to use? 0.2.0 | 0.3.2
    cohorts_to_drop_from_GT_Relatednes_check='' //# Which cohorts you do not want to perform GT relatedness check agains - this comes from your tsv file from genotype definitions
    provide_within_pool_donor_specific_sites_for_pilup = false //# If true pipeline will take the donors that you have indicated to be within each pool and provide cellsnp extra variant positions that are unique to the donors within pool
    hard_filters_drop = false //#This indicates whether we want to drop the cells that fail hard filters of just flag them
    add_snps_to_pile_up_based_on_genotypes_provided = false // #whether we want to add informative snp to pile up in bam to enhance deconvolutions.
    remove_work_dir = false
    RUN='default' //# Run name to be used in some of the final reports
    skip_qc=false
    skip_handover = false
    skip_merge = false
    just_reports = false
    normalise_andata = true
    skip_preprocessing = false
    do_deconvolution = true
    extra_metadata=''
    cluster_markers = false // # Should we perform cluster marker analysis
    cellex_cluster_markers = false // # Whether to find cluster markers using cellex

    copy_mode = "rellink"
    file__anndata_merged = ''
    gt_match_file="" // #We prvide this if we want to exclude a particular samples matched to a ceirtain GT cohortc from the adaptive qc
    gt_match_based_adaptive_qc_exclusion_pattern = '' // #We run the adaptive QC on these patterns independently regardless on assigned celltype.        
    file__cells_filtered = ''
    id_in='experiment_id'
    genotype_phenotype_mapping_file ='' //# genotype - phenotype mapping file
    extra_sample_metadata = ''
    use_phenotype_ids_for_gt_match = true //#if false this will keep the genotype ids, for this to be used have to set a genotype_phenotype_mapping_file to a path to csv where firs column contains genotype ids and second contains phenotype ids to replace these to.
    run_celltype_assignment = true
    cluster_validate_resolution_keras = true
    input_tables_column_delimiter = '\t'
    outdir= "${launchDir}/results" //# Default output directory
    tracedir                   = "${params.outdir}/pipeline_info" // # Default trace Dir

    doublet_celltype_split_column = 'None'  //# Column in .obs used to split the dataset into batches 
                                            // # for independent doublet detection and cell type annotation.
                                            // # Default is 'batch'. Set to 'None' to disable splitting.
    split_bam = false //# Should we generate a bam file per donor after the deconvolutions?
    utilise_gpu = true // # Should we use gpu for processes that support it?

    // # If you have already processed any of the bellow with yascp then you can provide a path to them and it will use the results provided instead of reruning these steps.
    existing_cellsnp="${projectDir}/assets/existing_cellsnp" // # You may want to avoid rerunning cellsnp. 
    existing_vireo="${projectDir}/assets/existing_cellsnp" //# Sometimes you may want to run vireo independently and provide the results to yascp - for example for chimera samples. 
    cellbender_location="${launchDir}/results" //# Cellbender runs very long and is recours demanding so its always a good idea to not reprocess it if you can. 

    // # Cellbender settings
    cellbender_resolution_to_use='0pt1' //# Which resolution to use. By default Yascp runs 0.01 0.05 0.1 as defined in bellow block
    cellbender_with_citeseq=false //# This is only available for the 0.3.1 cellender version. If you have selected this we will not remove extra modalities from the matrix efore subjecting it to the cellender. 
    cellbender_rb{
        description = 'Parameters for cellbender remove background.'
        // # you can specify per sample params, which will take priority over globals params bellow. Here the name should match the experiment_id in the input.tsv
        per_sample_thresholds = [
                [ name : 'H15672658', low_count_threshold : 5, epochs : 100 , learning_rate : 0.0001, zdim : 100, zlayers : 500, total_droplets_included: 1000, expected_cells: 1000],
        ]

        estimate_params_umis{
            description = """
                Cellbender requires two parameters=
                    (1) expected-cells
                    (2) total-droplets-included
                Expected number of cells: expected a priori from the experimental
                    design or based on the UMI curve at a point where one is
                    reasonably sure that all droplets to the left on the UMI
                    curve are real cells.
                Total droplets included: emtpy droplets. Point on the UMI curve
                    where every droplet to the right of this number on
                    the UMI curve should be surely empty.
                There are several ways to provide these parameters to this
                workflow:
                    (1) In the file_paths_10x.tsv file under the ncells_expected
                        ndroplets_include_cellbender columns
                    (2) Estimate both parameters via the
                        get_estimates_from_umi_counts.py script.
                get_estimates_from_umi_counts.py options for # of cells:
                    (1) method_estimate_ncells: method used to estimate knee or
                        inflection point on UMI plot.
                    (2) lower_bound_umis_estimate_ncells: remove cells with UMIs
                        below this bound before estimating the knee/inflection.
                get_estimates_from_umi_counts.py options for # of empty droplets:
                    (1) method_estimate_ncells: method used to estimate knee or
                        inflection point on UMI plot.
                    (2) lower_bound_umis_estimate_ncells: remove cells with UMIs
                        below this bound before estimating the knee/inflection.
                    (3) upper_bound_umis_estimate_ncells: remove cells with UMIs
                        above this bound before estimating the knee/inflection.
                    (4) estimate_nemptydroplets_umi_add_factor: after
                        identifying an inflection point add this number to
                        the umi counts to get the final cutoff point,
                    (5) expected_nemptydroplets_umi_cutoff: set the empty droplet
                        value using this umi cutoff.
                    (6) estimate_nemptydroplets_min_drop: if the estimated droplet
                        cutoff is < this value, then set it to this value.
                    (7) estimate_nemptydroplets_subtract_cell_factor: subtract this
                        number from the total number of cell estimates.
                If exact number per sample is provided in file_paths_10x.tsv via
                the ndroplets_include_cellbender column, then estimates are not
                performed and this parameter does nothing.
                NOTE: Setting this parameter will likely vary according
                    tissue / dataset - evaluate the UMI count plots across the
                    full dataset before setting.
                WARNING Do not attempt to iterate over many parameters here as
                    these settings are not recorded in the output dir.
                """

                value{
                    expected_nemptydroplets_umi_cutoff = 0
                    method_estimate_ncells = 'dropletutils::barcoderanks::inflection'
                    lower_bound_umis_estimate_ncells = 1000
                    method_estimate_nemptydroplets = 'dropletutils::barcoderanks::inflection,dropletutils::barcoderanks::knee,0.33'
                    lower_bound_umis_estimate_nemptydroplets = 10
                    upper_bound_umis_estimate_nemptydroplets = 250
                    estimate_nemptydroplets_umi_add_factor = 0
                    estimate_nemptydroplets_subtract_cell_factor = 0
                    estimate_nemptydroplets_min_drop = 0
                }
            }

            epochs{
                description = """CellBender parameter. Number of epochs for training.
                    CellBender default is 150."""
                value = 250
            }
            learning_rate{
                description = """CellBender parameter. Learning rate. If lower learning
                    rate, may need to increase the number of epochs.
                    CellBender default is 0.0001."""
                value = 0.000005
            }
            zdim{
                description = """Dimension of latent variable z, in v2 this parameter
                    influences the prior on cell counts.
                    https://github.com/broadinstitute/CellBender/issues/42
                    CellBender default is 100."""
                value = 100
            }
            zlayers{
                description = """Dimension of hidden layers in the encoder for z.
                    CellBender default is 500."""
                value = 500
            }
            low_count_threshold{
                description = """Droplets with UMI counts below this number are completely
                    excluded from the analysis. This can help identify the correct
                    prior for empty droplet counts in the rare case where empty
                    counts are extremely high (over 200).
                    CellBender default is 15."""
                value = 10
            }
            fpr{
                description = """CellBender parameter. A value of 0.01 is generally
                    quite good, but you can generate a few output count matrices
                    and compare them by choosing a few values: 0.01 0.05 0.1.
                    Target false positive rate in (0, 1). A false positive is a true
                    signal count that is erroneously removed. More background removal
                    is accompanied by more signal removal at high values of FPR.
                    You can specify multiple values, which will create multiple
                    output files.
                    CellBender default is 0.01."""
                value = "0.01 0.05 0.1"
            }

    }
    //# reference_assembly_fasta_dir = " /nfs/srpipe_references/downloaded_from_10X/refdata-gex-GRCh38-2020-A/fasta/"
    reference_assembly_fasta_dir = "https://yascp.cog.sanger.ac.uk/public/10x_reference_assembly"
    webtransfer = false
    project_name = 'Cardinal_pilots'
    tmpdir = "${launchDir}/work"

    //# eQTL{
    //#     eqtl_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/eqtl_26_10_2022.img'
    //#     aggregation_collumn='Azimuth:predicted.celltype.l2'
    //#     n_min_cells = '5' // #The number of cells for individual to use. 
    //#     n_min_individ = '30' // #Do not select less than 25 since this may result in a permutation issue with tensorqtl
    //#     aggregation_method = 'dMean,dSum'
    //# }

    citeseq_config{
        hastag_multiplexing_capture_labels = '"Hastag_.*,Another_Label"' //# These list hastag labels, these can be part of either antibody capture or in independent data modality. This works with regex. They can be ' ' or ',' seperated
    }

	genotype_input {
        subset_genotypes = false // # if activated this will use the IDs provided in the input.tsv to to perform the GT match against, otherwise it will match against full cohort.
        run_with_genotype_input= false // #Whether we are using genotypes in our runs.
        vireo_with_gt=false // #if activated this will run vireo with genotypes.
        subset_vireo_genotypes = true // # This is a switch that determines whether we want to provide full genotype file in the vireo as an input or subset it down to the expected donors. NOTE: you may want to provide already merged shards for this, otherwise pipeline will merge this for you.
        posterior_assignment = false // #if this is set to true, we will perform the genotype donor matching after the deconvolution is performed.
        tsv_donor_panel_vcfs = "" // #tlist of vcf/bcf inputs 1) Can be a single file in this tsv file 2) Can be multiple cohorts (in cases where we dont want to merge the genotypes together) 3) Can be sharded inputs (for example per chromosome)
        ZSCORE_THRESH = 3 //# Minimum z0 threshold required to call the gt assignment confident. 
        ZSCORE_DIST_THRESH = 3 //# Minimum bifference between z0 and z1 to call the assignment confident,
        genotype_correlation_threshold = 0.6 //# Threshod to be used to determine sample correlation and which samples are coming from same donor. 
    }

    use_bam_derived_cellsnp_panel = false // ##this will pile up variants in each of the bams to derive positions with a read coverage to use in deconvolutions - Note that your bams may or may not have chr prefix. You need to match your panels for gt match to have or not have the chr prefix too. 
    mpileup_extra_options = "" // #When deriving panels dynamically from a bam file you can specify any extra options you may want to use for the comand. 
    cellsnp {
        run = true
        remove_workdir = false
        copy_mode = "rellink"
        vcf_candidate_snps = "https://yascp.cog.sanger.ac.uk/public/cellsnp/genome1K.phase3.SNP_AF5e2.chr1toX.hg38.vcf.gz" // This panel will be used if you havent provide your own or you havent selected an option to use_bam_derived_cellsnp_panel
        description = """// this list of candidate SNPs for cellSNP comes from link at https://github.com/single-cell-genetics/cellSNP
        // i.e., https://sourceforge.net/projects/cellsnp/files/SNPlist/genome1K.phase3.SNP_AF5e2.chr1toX.hg38.vcf.gz/download"""
        min_maf = " --minMAF 0.1"
        min_count = "--minCOUNT 20"
        p = "20"
        UMItag=' --UMItag UB'
        cellTAG='CB'
        minMAPQ = '--minMAPQ 20'
    }

    vireo {
        run = true
        remove_workdir = false
        copy_mode = "rellink"
        run_gtmatch_aposteriori = true
        do_vireo_subsampling = true
        subsample_times=10
        rate=60
   }

    plot_donor_ncells {
        run = false
        remove_workdir = false
        copy_mode = "rellink"
        plotnine_dpi = "100"
    }

    souporcell {
        run = true
        use_raw_barcodes = false
        remove_workdir = false
        copy_mode = "rellink"
        reference_fasta = "https://yascp.cog.sanger.ac.uk/public/10x_reference_assembly/genome.fa"
     }


    plot_souporcell_vs_vireo {
        run = false
        remove_workdir = false
        copy_mode = "rellink"
    }

    cellsnp_recapture ='1'
    split_h5ad_per_donor {
        run = true
        remove_workdir = false
        copy_mode = "rellink"
        input_h5_genome_version = "GRCh38"
        print_modules_version = "True"
        plot_n_cells_per_vireo_donor = "True"
        write_donor_level_filtered_cells_h5 = "True"
        plotnine_dpi = "100"
        anndata_compression_level = "6"
    }

    anndata_compression_opts = 9
    doublets_and_celltypes_on_cellbender_corrected_counts = true //# Run doublet detection and cell type annotation on CellBender-corrected counts instead of raw data
    
    normalise{
        mode    = "conventional"
        layer = "none"
        minimum_number_of_cells_for_donor = 3 //# The minimum number of cells that the donor should have. This shouldnt be less than 3 cells.

        gene_filters{
            description = """Parameters for sample QC prior to merge.
                Filters are applied to all samples."""
            //# genes_exclude = 'IG[HKL][VDJ]|AC233755.*|IGH[GMDEA]|IGKC|IGLC|IGLL|TR[ABGD][CVDJ]' //# this can be a file, rejex pattern or a list of comma separated gene names
            genes_exclude = ''
            variable_genes_exclude = "${projectDir}/assets/genes_remove_hvg_v001.tsv" //# list of hvg to still keep if no geenes are needed to be excluded from integration and clustering then please provide: "no_file__genes_exclude_hvg"
            genes_at_least_in_nr_cells = 5 //# keep genes that are expressed in ceirtain amount of cells.
        }

        genes_score = "${projectDir}/assets/genes_score_v001.tsv" //# If no gene scoring is needed please provide "no_file__genes_score"
        drop_cell_passes_qc_from_clustering = false //#This filter if set to true will drop the cells that dont pass the adaptive qc criteria before clustering.
        
    }

    reduced_dims{
        run_downstream_analysis = false
        description = """Parameters for dimensionality reduction (principal component, seurat
        and harmony calculations). All pairwise combinations of
        vars_to_regress and n_dims will be performed."""

        vars_to_regress{
            description = """Comma separated string of variables to regress. Use "" to
            indicate no regession is to be performed. Use ; separation to regress multiple values simultaneously in the same run"""
            //# value = 'pct_counts_gene_group__mito_transcript'
            value = ''
            
        }

        n_dims{
            description =  """Number of dimensions to use for calculating PCs,
            harmony corrected PCs, and clusters. Value should be int.
            If auto_estimate == true then the 'knee' of a scree plot is
            automatically estimated via the kneedle algorithm and used.
            If auto_estimate == true then value is ignored.
            add_n_to_estimate is added to the elbow estimate."""
            auto_estimate = true
            add_n_to_estimate = 5
            value = 30
        }
        seurat_integration{
            k_anchor = 4 //# integrate sct
            dims = 10
            ndim_sct = 10 //# Number of dimensions to use for SCT integrated data (check elbow plot to see if it's correct)
            ndim_citeBgRemoved = 10 //# Number of dimensions to use for cite_bgRemoved integrated data (check elbow plot to see if it's correct)
            ndim_cite_integrated = 10 //# Number of dimensions to use for cite integrated data (check elbow plot to see if it's correct)
        }

    }

    filter_multiplets{
        run_process = true
        expected_multiplet_rate = 0.1 //# used for scrublet and doubletFinder.
        
        doubletDetection{
             run_process = false           
        }
        doubletDecon{
            run_process = true
        }

        scDblFinder{
            run_process = true
        }
        scds{
            run_process = true
        }
        doubletFinder{
            run_process = true
        }

        scrublet{
            description = """Parameters for scrublet. Runs prior to filters
                below. Note scale_log10 should be 'True|False'.
                Output from multiplet analysis will be added to the final
                AnnData object. The flag only works if
                file_cellmetadata from the main nextflow call is not set."""
            run_process= true
            n_simulated_multiplet= 100000
            multiplet_threshold_method = 'threshold_li'
            scale_log10 = 'False'
        }
    }

    celltype_assignment{
        run_celltype_assignment = true
        run_azimuth = true
        run_scpred = true
        run_keras = false
        run_celltypist = true
    }
    mapping_file = "${projectDir}/assets/azimuth/Azimuth_Mappings.txt"
    
    scpred{
        reference = "https://yascp.cog.sanger.ac.uk/public/celltype/scpred/hier_scpred.RDS"
    }
    
    metadata_key_column{
            description = """Column in metadata that matches the experiment_id column in
        tenx_data."""
            value = 'experiment_id'
    }

    mads_categories ='pct_counts_gene_group__mito_transcript,pct_counts_gene_group__mito_protein,pct_counts_gene_group__ribo_protein,pct_counts_gene_group__ribo_rna,total_counts,n_genes_by_counts'

    celltype_prediction {
        //# this is bespoke model from Anderson lab for IBD research to anothate cells.
        keras {
            keras_model = 'https://yascp.cog.sanger.ac.uk/public/celltype/keras/keras_606D0E926847C0A1_clustered.h5'
            keras_weights_df = 'https://yascp.cog.sanger.ac.uk/public/celltype/keras/keras_606D0E926847C0A1_weights.tsv.gz'
            h5_layer = 'log1p_cp10k'
            keras_model_cluster_labels = "${projectDir}/assets/keras_cluster/data-cluster_labels.csv"
            filter_top_cell_probabilities = '0.5,0.75'
            save_all_probabilities = '--save_all_probabilities'
	    }
    }

    celltypist {
        //# Celltypist models to use
        description = """https://github.com/Teichlab/celltypist"""
        models = ["Immune_All_High.pkl","Immune_All_Low.pkl","COVID19_Immune_Landscape.pkl"]
        //# OPTIONS for pre-Downloaded models (otherwise download pkl files from celltypist to use a different or more up to date models):
        //# Adult_Mouse_Gut.pkl         COVID19_Immune_Landscape.pkl  Human_IPF_Lung.pkl    Lethal_COVID19_Lung.pkl
        //# Autopsy_COVID19_Lung.pkl    Developing_Human_Brain.pkl    Human_Lung_Atlas.pkl  models.json
        //# Cells_Fetal_Lung.pkl        Developing_Human_Thymus.pkl   Human_PF_Lung.pkl     Nuclei_Lung_Airway.pkl
        //# Cells_Intestinal_Tract.pkl  Developing_Mouse_Brain.pkl    Immune_All_High.pkl   Pan_Fetal_Human.pkl
        //# Cells_Lung_Airway.pkl       Healthy_COVID19_PBMC.pkl      Immune_All_Low.pkl
    }

    cell_hard_filters = true //# whether to perform annotation of cells that would not pass hard filters defined in the folowing block - sample_qc.cell_filters.all_samples|experiment
    sample_qc{

        description = """Parameters for sample QC prior to merge.
            Filters are applied to all samples."""
        cell_filters{
            run_process = true
            description = """Cell filters. Each bullet point is a seperate filter.
            Cells that evaluate to true for any of these filters, will be
            removed. Filters under 'all_samples' are applied to all samples.
            Filters under a sample id are applied to that specific sample."""

            //# Hard filters for all the samples
            all_samples{
                value = 'pct_counts_gene_group__mito_transcript > 20 or n_genes_by_counts < 500 or log10_ngenes_by_count < 0.8' // if nothing please place '' ; for multiple filters please split it with ; or ,
            }

            //# Hard filters for specific samples - takes priority over the all samples.
            experiment{
                // value = '' //# If you would like to apply hard filters per specific experiment please provide: experiment_id:'pct_counts_gene_group__mito_transcript > 20;experiment_id2:'n_genes_by_counts < 500'
                value = "experiment_id:'pct_counts_gene_group__mito_transcript > 20';experiment_id2:'n_genes_by_counts < 500'"
            }

            //# These are the adaptive filters - MAD or Isolation forest or other approack. Multiple methods can e used and then downstream can be evaluated which yields the most sensible results.
            filter_outliers{
                description = """After applying cell filters based on cutoffs, apply
                    an filter to remove outliers using cell information from
                    metadata_columns.
                    Recommended settings:
                        method: IsolationForest
                        metadata_columns: n_cells
                        outliers_fraction: 0.0
                        max_cells: 0.1 or 0.99
                    Notes:
                    * Filters applied across the full dataset (i.e., not on a per
                        sample level).
                    * Valid methods: LocalOutlierFactor, IsolationForest,
                        EllipticEnvelope, OneClassSVM.
                    * outliers_fraction: anticipated fraction of outlier cells.
                        If 0.0, then runs sklearn methods with 'auto' as the
                        anticipated number of outlier cells.
                    * max_samples: The fraction of cells to draw from X to train
                        each estimator. Only valid if method == IsolationForest."""
                run_process = true
                method = 'IsolationForest,MAD' //# Available methods: localOutlierFactor, IsolationForest, EllipticEnvelope, OneClassSVM, MAD
                mad_tresholds = '-3,-3,3' //# These one side MAD filters will be used if selected. If MAD is used then these thresholds will be used for each of them. [-] prefix means filtering on the left side of distribution, whereas [+] means filtering on the right side of distribution.
                outliers_fraction = 0.0
                max_samples = 0.1
                methods_thresholds = [
                        [ method : 'MAD', metadata_columns : 'log1p_total_counts,log1p_n_genes_by_counts,pct_counts_gene_group__mito_transcript', mad_tresholds : "-3,-3,3", outlier_filtering_strategy:'all_together'],
                        [ method : 'IsolationForest', metadata_columns : 'log1p_total_counts,log1p_n_genes_by_counts,pct_counts_gene_group__mito_transcript', outlier_filtering_strategy:'all_together'],
                    ]
            }
        }
        
        gt_match_based_adaptive_qc_exclusion_pattern = '' // # You may have spikeins in your samples. Provide genotype IDs of the samples that you want to avoid from MAD filters. We run the adaptive QC on these patterns independently regardless on assigned celltype.  

        // # Here you can downsample cells down to ceirtain percentage to make integration and clustering more scalable for large cohorts
        downsample_cells_fraction{
            description = """Downsample to this fraction of the number of
                observations (sc.pp.subsample). Use "" to indicate no downsampling.
                Example: if 0.8, will drop 20% of cells."""
            value= ''
        }

        downsample_cells_n{
            description = """Downsample to this number of observations
                (sc.pp.subsample). Use "" to indicate no downsampling. Example: if
                200 then 200 total cells will be kept."""
            value = ''
        }

        downsample_feature_counts{
            description = """Downsample the number of feature counts by this fraction.
                Use "" to indicate no downsampling."""
            value = ''
        }

    }

    // # QC plots and the settings
    plots_qc{

        description = """Parameters for basic QC plots after sample merge. All
        pairwise combinations of facet_columns and
        variable_columns_distribution_plots will be performed."""
        facet_columns{
            description = 'Column to facet all QC plots by.'
            value = 'experiment_id'
        }

        variable_columns_distribution_plots{
            description= """Plot the distributions of these variables (histogram and
            ecdf)."""
            value = 'total_counts,pct_counts_gene_group__mito_transcript'
        }

    }

    dont_integrate_just_cluster=false //#whether to skip integration steps and just use unintegrated results as per of the clustering
    
    //#Harmony parameters for integration
    harmony{ 
        run_process= true
        description = 'Parameters for harmony'
        variables_and_thetas{
            description = 'Tuples of metadata columns and corresponding thetas'
            value = [
                [ variable: 'experiment_id', theta: 1.0 ],
            ]
        }
    }

    //#BBKNN parameters for integration
    bbknn{
        run_process = true
        description = 'Parameters for BBKNN'
        estimate_neighbors = true //# we wil use the number of neighbors as per bbknn i.e Total number of neighbours = neighbors_within_batch x the number of
        batch_variable{
            description = 'Variable to use for batch correction'
            value = 'experiment_id'
        }
    }

    // #TotalVI params and options
    totalVi{ 
        run_process=false
    }

    //#Should we perform seurat integration - this is very slow process and works only on small datasets
    seurat_integration{
        run_process=false
    }

    // # LISI options
    lisi{
        run_process = false
        description = 'Parameters for Local Inverse Simpsons Index (LISI).'
        variables{
            description = 'Metadata variables to compute LISI over.'
            value = 'experiment_id'
        }
    }

    // #Clustering options 
    cluster{
        description = """Parameters for clustering. All pairwise combinations of
        method and resolution will be performed."""
        number_neighbors{
            description = """Number of neighbors. If <= 0, uses number of unique
            experiment_id."""
            value = 15
        }
        methods{
            description = 'Clustering method. Valid options [leiden|louvain].'
            value = 'leiden'
        }
        resolutions{
            description = 'Clustering resolution.'
            value = [0.1,0.5,1.0,5.0]
        }

        variables_boxplot{
            decription = 'Generate boxplots of these variables for each cluster.'
            value ='n_cells,total_counts,pct_counts_gene_group__mito_transcript'
        }

        known_markers{
             run_process = false
             value = []
                //# // {file_id: 'SmillieCS_31348891', file: '/lustre/scratch119/humgen/projects/sc-eqtl-ibd/data/marker_gene_db-raw_data/database/celltypes/colon/SmillieCS-31348891/database.tsv'},
                //# // [ file_id: 'ParikhK_30814735', file: '/lustre/scratch119/humgen/projects/sc-eqtl-ibd/data/marker_gene_db-raw_data/database/celltypes/colon/ParikhK-30814735/database.tsv'],
                //# // [ file_id: 'JamesKR_32066951', file: '/lustre/scratch119/humgen/projects/sc-eqtl-ibd/data/marker_gene_db-raw_data/database/celltypes/colon-immune/JamesKR-32066951/database.tsv']
             
         }
    }

    // # Validate resolutions of clusters options
    cluster_validate_resolution{
            description = 'Parameters for cluster resolution validation.'
            sparsity{
                description =  """LogisticRegression sparsity or inverse of regularization
                strength; must be a positive float. Like in support vector
                machines, smaller values specify stronger regularization."""
                value = 0.0001
            }
            train_size_cells{
                description = """Number of cells to use for training. Set to -1 for
                    to use default of 2/3 of total cells. Do not change this parameter
                    unless you know what you are doing."""
                value = -1
            }
        }

    // # Derive cluster markers options
    cluster_marker{
            description = 'Parameters for identifying cluster marker features.'
            methods{
                description = 'Method for marker detection. Valid options [wilcoxon|logreg].'
                        value = 'wilcoxon'
            }
        }

    // # UMAP production options
    umap{
        run_process = true
        description = 'Parameters for umap.'
        colors_quantitative {
            description = 'Comma separated string of quantitative variables that will be used to color points.'
            value = "^cell_passes_qc-.*:score\$,S_score,G2M_score,n_cells,^Azimuth:.*(score|mapping\\.score.*)\$,^Celltypist:[^:]+:conf_score\$,^doublet:.*(Score|score|scores)\$,total_counts,pct_counts_gene_group__mito_transcript,prob_doublet,pct_counts_gene_group__ribo_rna,Azimuth:predicted.celltype.l2.score,Azimuth:mapping.score,log10_ngenes_by_count"
        }

        colors_categorical {
            description = 'Comma separated string of categorical variables that will be used to color points.'
            value = "^cell_passes_qc-[^:]+(?:-[^:]+)*(:[^:]+)?\$,Hastag.*,hastag.*,phase,experiment_id,cell_passes_qc-MAD-3,\"-3\",\"3-per:all_together\",cell_passes_qc,cell_passes_hard_filters,^doublet:.*(DropletType|predicted_multiplet)\$,^Celltypist:[^:]+:predicted_labels\$,^Azimuth:(L\\d+_)?predicted\\.celltype\\.l\\d+\$"
        }
        n_neighbors{
            description = """Number of neighbors for sc.pp.neighbors call.
                Recommended value between 2-100. If you expect each cell type
                cluster to be shared across all experiments/samples, then setting
                this number to the number of experiments/samples is a good place to
                start. Note: values separated with a comma will be run within the
                same script call (rather than swarm)."""
            value= [15,50]
        }

        umap_init{
            description = 'How to initialize the low dimensional embedding.'
            value = 'spectral'
        }
        umap_min_dist{
            description = """The effective minimum distance between embedded points.
                Recommended value between 0-1. Note: values separated with a comma
                will be run within the same script call (rather than swarm)."""
            value = 0.5
        }

        umap_spread{
            description = """The effective scale of embedded points.
                Recommended value between 0-3. Note: values separated with a comma
                will be run within the same script call (rather than swarm)."""
            value = 1.0
        }
    }

    // # SCCAF cluster assesment options
    sccaf{
        description = 'sccaf'
        run_assessment = true
        run_optimization = false
        min_accuracy = 0.92
        default_leiden_res = 4.0
    }
    
    // # Azimuth celltype options and models
    remap_celltypes = true // # For PBMCs we also map the l2 anotations to less granual annotations
    azimuth{
        run_process = true
        celltype_refsets = [
                //# [ name : 'kidney', refset : "/lustre/scratch123/hgi/teams/hgi/mo11/tmp_projects/jaguar_yascp/nieks_pipeline/yascp_run/ref_kidney", annotation_labels : "cluster,subclass" ],
                [ name : 'PBMC', refset : "PBMC", annotation_labels : "celltype.l2,celltype.l1,celltype.l3" ],
            ]
        celltype_atac_refsets = [
                //# [ name : 'kidney', refset : "/lustre/scratch123/hgi/teams/hgi/mo11/tmp_projects/jaguar_yascp/nieks_pipeline/yascp_run/ref_kidney", annotation_labels : "cluster,subclass" ],
                [ name : 'PBMC', refset : "PBMC", annotation_labels : "celltype.l2,celltype.l1,celltype.l3" ],
            ]
    }

    rsync_to_web_file = "${launchDir}/yascp/bin/rsync_to_web.sh" //# we have a dedicated server which stores summary stats to visualise data, this is sanger specific

}
