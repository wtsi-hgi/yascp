#!/usr/bin/env python


__date__ = '2021-01-20'
__version__ = '0.0.1'
# sklearn version used = 0.24.2
import argparse
import random
import os
os.environ['NUMBA_CACHE_DIR']='/tmp'
os.environ['MPLCONFIGDIR']='/tmp'
from distutils.version import LooseVersion
import numpy as np
import scanpy as sc
import pandas as pd
from sklearn.svm import OneClassSVM
from sklearn.covariance import EllipticEnvelope
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import matplotlib
matplotlib.use('Agg')
y_n_print=False
# import matplotlib.pyplot as plt
# matplotlib.style.use('ggplot')
import seaborn as sns

# Set seed for reproducibility
seed_value = 0
# 0. Set `PYTHONHASHSEED` environment variable at a fixed value
os.environ['PYTHONHASHSEED'] = str(seed_value)
# 1. Set `python` built-in pseudo-random generator at a fixed value
random.seed(seed_value)
# 2. Set `numpy` pseudo-random generator at a fixed value
np.random.seed(seed_value)


# Fit the model
def perform_adaptiveQC_Filtering(clf,adata,method,metadata_columns):
    # We return labels of the Treue/False of failing QC
    if method == 'LocalOutlierFactor':
        # use fit_predict to compute the predicted labels of the training
        # samples (when LOF is used for outlier detection, the estimator has
        # no predict, decision_function and score_samples methods).
        f = clf.fit_predict(
            adata.obs[metadata_columns].values
        ) == 1
        predicted_scores = clf.negative_outlier_factor_
    elif method == 'IsolationForest':
        f = clf.fit_predict(
            adata.obs[metadata_columns].values
        ) == 1
        predicted_scores = clf.decision_function(adata.obs[metadata_columns].values) 
    else:
        f = clf.fit_predict(
            adata.obs[metadata_columns].values
        ) == 1
        predicted_scores = clf.decision_function(adata.obs[metadata_columns].values)

    return predicted_scores,f

def generate_plots(adata,cell_qc_column,metadata_columns,metadata_columns_original,of):
    # Plot the identified outliers
    
   
    # print("Making plot")

    sns_plot = sns.PairGrid(
        adata.obs[metadata_columns],
        hue=cell_qc_column,
        height=2.5,
        diag_sharey=False
    )
    sns_plot.map_upper(
        sns.scatterplot,
        marker='+',
        alpha=0.05,
        s=8,
        edgecolor=None
    )
    sns_plot.add_legend()
    for lh in sns_plot._legend.legendHandles:
        lh.set_alpha(1)
        lh._sizes = [50]
    sns_plot.map_diag(sns.kdeplot)
    sns_plot.map_lower(
        sns.kdeplot,
        levels=3
    )
    sns_plot.savefig(f'{of}-outlier_cells__{cell_qc_column}.png')

    # Plot the cell density
    # print("Making density plot")
    sns_plot = sns.PairGrid(
        adata.obs[metadata_columns_original],
        height=2.5,
        diag_sharey=False
    )
    sns_plot.map_upper(
        sns.kdeplot,
        cmap="viridis",
        shade=True
    )
    sns_plot.add_legend()
    for lh in sns_plot._legend.legendHandles:
        lh.set_alpha(1)
        lh._sizes = [50]
    sns_plot.map_diag(sns.kdeplot)
    sns_plot.map_lower(
        sns.kdeplot,
        cmap="viridis",
        shade=True
    )
    sns_plot.savefig(f'{of}-cell_desity__{cell_qc_column}.png')
    
            
def main():
    """Run CLI."""
    parser = argparse.ArgumentParser(
        description="""
            Performs automatic outlier detection over an anndata dataset,
            plotting the outlier cells.
            """
    )

    parser.add_argument(
        '-v', '--version',
        action='version',
        version='%(prog)s {version}'.format(version=__version__)
    )

    parser.add_argument(
        '-h5', '--h5_anndata',
        action='store',
        dest='h5',
        required=True,
        help='H5 AnnData file.'
    )
    
    parser.add_argument(
        '-gt', '--gt_match_file',
        action='store',
        dest='gt_match_file',
        default=None,
        required=False,
        help='H5 AnnData file.'
    )    
    
    parser.add_argument(
        '-pt', '--patterns_exclude',
        action='store',
        dest='patterns_exclude',
        default=None,
        required=False,
        help='H5 AnnData file.'
    )    
    
    parser.add_argument(
        '--outliers_fraction',
        action='store',
        dest='outliers_fraction',
        default=0.0,
        type=float,
        help='Anticipated fraction of outlier cells. If 0.0, then runs sklearn \
            methods with "auto" as the anticipated number of outlier cells.\
            (default: %(default)s)'
    )

    parser.add_argument(
        '--metadata_columns',
        action='store',
        dest='metadata_columns',
        default='pct_counts_gene_group__mito_transcript,log1p_total_counts,log1p_n_genes_by_counts',
        help='Columns to use for outliers.\
            (default: %(default)s)'
    )

    parser.add_argument(
        '--cell_qc_column',
        action='store',
        dest='cell_qc_column',
        default='cell_passes_qc',
        help='If column exists, cells are first filtered for those that \
            evaluate to true in this column, then this column is updated \
            based on the QC filtering. If this column does not exist then \
            it is added. \
            (default: %(default)s)'
    )

    parser.add_argument(
        '--method',
        action='store',
        dest='method',
        default='IsolationForest',
        help='Method for outlier detection. \
            (default: %(default)s)'
    )

    parser.add_argument(
        '--max_samples',
        action='store',
        dest='max_samples',
        default=0.1,
        type=float,
        help='The fraction of cells to draw from X to train each estimator. \
            Only valid if method == IsolationForest. \
            (default: %(default)s)'
    )
    # TODO: add option where user can say "run per each experiment id"

    parser.add_argument(
        '--cell_filtered_per_experiment_file',
        action='store',
        dest='cell_filtered_per_experiment',
        default='None',
        help='File detailing samples filtered per experiment. \
            (default: %(default)s)'
    )

    parser.add_argument(
        '-of', '--output_file',
        action='store',
        dest='of',
        default='outliers',
        help='Basename of output files. \
            (default: %(default)s)'
    )
    parser.add_argument(
        '-fs', '--filter_strategy',
        action='store',
        dest='outlier_filtering_strategys',
        default='all_together',
        help='By default we filter the outliers for all the cells provided together, \
            but we may want to run it per celltype'
    )

    parser.add_argument(
        '--anndata_compression_opts',
        action='store',
        dest='anndata_compression_opts',
        default=4,
        type=int,
        help='Compression level in anndata. A larger value decreases disk \
            space requirements at the cost of compression time. \
            (default: %(default)s)'
    )

    options = parser.parse_args()

    # Get compression opts for pandas
    compression_opts = 'gzip'
    if LooseVersion(pd.__version__) > '1.0.0':
        compression_opts = dict(method='gzip', compresslevel=9)

    # Load the AnnData file.
    adata = sc.read_h5ad(filename=options.h5)
    adata.obs['cell_id'] = adata.obs.index
    adata_original = adata.copy()
    # Here we add an adaptive QC per Column
    # Drop out previous QCed cells
    cell_qc_column = options.cell_qc_column
    if cell_qc_column in adata.obs.columns:
        n_cells_original = adata.shape[0]
        adata = adata[adata.obs[cell_qc_column], :]
        print('Filtered out {} previously flagged cells using {}'.format(
            n_cells_original - adata.shape[0],
            cell_qc_column
        ))
    else:
        adata.obs[cell_qc_column] = True

    # Get ballpark number of outliers
    outliers_fraction = options.outliers_fraction
    n_cells = adata.shape[0]
    n_outliers = outliers_fraction * n_cells
    if n_outliers == 0:
        outliers_fraction = 'auto'

    # Get a list of the data to use to calculate outliers
    metadata_columns = options.metadata_columns.split(',')
    # metadata_columns = [
    #     'pct_counts_gene_group__mito_transcript',
    #     #'total_counts',
    #     'log1p_total_counts',
    #     #'n_genes_by_counts',
    #     'log1p_n_genes_by_counts'
    # ]

    method = options.method
    if method == 'LocalOutlierFactor':
        # fit the model for outlier detection (default)
        clf = LocalOutlierFactor(
            #n_neighbors=100,
            # contamination=outliers_fraction
        )
    elif method == 'IsolationForest':
        max_samples = options.max_samples
        # if max_samples == 0.0:
        #     if n_cells < 1000:
        #         max_samples = 250
        #     else:
        #         max_samples = 0.1
        print("Using max_samples of:\t{}".format(max_samples))
        clf = IsolationForest(
            #n_estimators=500,
            max_samples=max_samples,
            warm_start=False,
            contamination=outliers_fraction,
            random_state=0,
            bootstrap=True
        )
    elif method == 'EllipticEnvelope':
        if outliers_fraction == 'auto':
            outliers_fraction = 0.1
        clf = EllipticEnvelope(
            contamination=outliers_fraction
        )
    elif method == 'OneClassSVM':
        clf = OneClassSVM(
            # nu=n_outliers,
            # kernel="rbf",
            # gamma=0.1
        )
    else:
        raise ValueError('ERROR: invalid method.')

    metadata_columns_original = metadata_columns.copy()
    # We perform the adaptive qc either for all data together or per user defined column of unique values.
    outlier_filtering_strategys = options.outlier_filtering_strategys
    outlier_filtering_strategys = 'Azimuth:L0_predicted.celltype.l2;all_together;all_together::exclude'
    outlier_filtering_strategys = outlier_filtering_strategys.split(';')
    matching = [s for s in outlier_filtering_strategys if "::" in s]
    for m1 in matching:
        # duplicate the strategy if we have flagged it as an extra step by adding ::no_exclude flag
        m2 = m1.split('::')[0]
        if m1 =='all_together::exclude':
            adata.obs[m1] = 'all_cells'
        else:
            adata.obs[m1] = m2
        
    # We load the GT match file and determine the celline match that needs to be subjected to adaptive qc independently
    if(options.patterns_exclude):
        ######## The folowing bit of code takes the GT match outputs and utilises this to run adaptive qc on cellines independently - only if the celline is expected.
        if(options.gt_match_file!='fake_file.fq'):
            GT_match_file = pd.read_csv(options.gt_match_file,sep='\t')
            GT_patterns = options.patterns_exclude.split(';')
            for outlier_filtering_strategy in outlier_filtering_strategys:
                strategy = outlier_filtering_strategy
                if strategy!='all_together':
                    for pattern in GT_patterns:
                        Matches = GT_match_file[GT_match_file['donor_gt'].str.contains(pattern)]
                        if len(Matches)>0:
                            for i,match in Matches.iterrows():
                                donor=match['donor_query']
                                pool=match['pool']
                                expected = match['Match Expected']
                                if expected:
                                    filter_query = f"convoluted_samplename=='{pool}' and Donor=='{donor}'"
                                    idx1 = adata.obs.query(filter_query).index
                                    try:
                                        adata.obs[strategy] = adata.obs[strategy].cat.add_categories(pattern)
                                    except:
                                        _='category exists already'
                                    adata.obs.loc[idx1,strategy]=pattern
        ########                 
    # all_index = pd.DataFrame(adata.obs.index,columns=['col'])
    # all_together = all_indexes.str[0]+'-'+all_indexes.str[1]+'-'+all_indexes.str[2]
    
    for outlier_filtering_strategy in outlier_filtering_strategys:
        metadata_columns = metadata_columns_original.copy()
        if (outlier_filtering_strategy == 'all_together'):
            cell_qc_column = options.cell_qc_column
            adata.obs[cell_qc_column] = True
            adata.obs[f"{cell_qc_column}:score"] = None
            metadata_columns.append(cell_qc_column)
            prediction_score, fail_pass = perform_adaptiveQC_Filtering(clf,adata,method,metadata_columns)
            adata.obs[cell_qc_column] = fail_pass
            adata.obs[f"{cell_qc_column}:score"] = prediction_score
        else:
            cell_qc_column = f'{cell_qc_column}-per:{outlier_filtering_strategy}'
            metadata_columns.append(cell_qc_column)
            adata.obs[cell_qc_column] = True
            adata.obs[f"{cell_qc_column}:score"] = None
            try:
                os.mkdir(f'per_celltype_outliers__{outlier_filtering_strategy}')
            except:
                _='exists already'
            try:
                outlier_strategy_cols = set(adata.obs[outlier_filtering_strategy])
            except:
                print('user provided col doesnt exist')
                continue
            for subset_id_for_ad_qc in outlier_strategy_cols:
                subset_ad = adata[adata.obs[outlier_filtering_strategy]==subset_id_for_ad_qc]
                    
                if(len(subset_ad)>100):
                    # We only perform adaptive qc when there is at least 100 cells, otherwise we assume that all pass
                    prediction_score, fail_pass = perform_adaptiveQC_Filtering(clf,subset_ad,method,metadata_columns)
                    adata.obs.loc[subset_ad.obs.index,cell_qc_column]=fail_pass
                    subset_ad.obs.loc[subset_ad.obs.index,cell_qc_column]=fail_pass
                    
                    adata.obs.loc[subset_ad.obs.index,f"{cell_qc_column}:score"]=prediction_score
                    subset_ad.obs.loc[subset_ad.obs.index,f"{cell_qc_column}:score"]=prediction_score
                    
                else:
                    print(f'For a category {subset_id_for_ad_qc} we have only {len(subset_ad)} cells and as its not sufficient ammount to estimate distributions we assuma all pass QC')
                subset_ad.uns['cell_outlier_estimator'] = method
                of = f'per_celltype_outliers__{outlier_filtering_strategy}/{subset_id_for_ad_qc}---{options.of}'
                generate_plots(subset_ad,cell_qc_column,metadata_columns,metadata_columns_original,of)
        adata.uns['cell_outlier_estimator'] = method  
           
        # Update the original data to flag those cells that passed the outlier
        adata_original.obs[cell_qc_column] = False
        adata_original.obs.loc[
            adata.obs['cell_id'][adata.obs[cell_qc_column]],
            cell_qc_column
        ] = True
        adata_original.obs[['cell_id', cell_qc_column]].to_csv(
            f'{options.of}-outliers_filtered__{cell_qc_column}.tsv.gz',
            sep='\t',
            compression=compression_opts,
            index=False,
            header=True
        )



        # Calculate cell_filtered_per_experiment
        filter_columns = [
            'experiment_id',
            'filter_type',
            'n_cells_left_in_adata'
        ]
        if options.cell_filtered_per_experiment == 'None':
            df_cell_filt_per_exp = adata.obs['experiment_id'].value_counts()
            df_cell_filt_per_exp = df_cell_filt_per_exp.rename_axis(
                'experiment_id'
            ).reset_index(name='n_cells_left_in_adata')
            df_cell_filt_per_exp['filter_type'] = 'before_filters'
            df_cell_filt_per_exp = df_cell_filt_per_exp[filter_columns]
        else:
            # Load the samples filtered per experiment file:
            df_cell_filt_per_exp = pd.read_csv(
                options.cell_filtered_per_experiment,
                sep="\t"
            )
            filt = df_cell_filt_per_exp['filter_type'] != 'after_filters'
            df_cell_filt_per_exp = df_cell_filt_per_exp.loc[filt, :]
            
        # Now calculate the n cells left after all filters
        adata_after_filters = adata.obs.loc[adata.obs[cell_qc_column], :]
        df_cells_filtered = adata_after_filters['experiment_id'].value_counts()
        df_cells_filtered = df_cells_filtered.rename_axis(
            'experiment_id'
        ).reset_index(name='n_cells_left_in_adata')
        df_cells_filtered['filter_type'] = '{} {} outlier_{}'.format(
            'filter__all_samples',
            'after_outlier_filter',
            method
        )
        df_cells_filtered = df_cells_filtered[filter_columns]
        df_cell_filt_per_exp = df_cell_filt_per_exp.append(
            df_cells_filtered,
            ignore_index=True
        )
        df_cells_filtered['filter_type'] = 'after_filters'
        df_cell_filt_per_exp = df_cell_filt_per_exp.append(
            df_cells_filtered,
            ignore_index=True
        )
        # Save the final dataframe
        df_cell_filt_per_exp.to_csv(
            f'{options.of}-cell_filtered_per_experiment__{cell_qc_column}.tsv.gz',
            sep='\t',
            compression=compression_opts,
            index=False,
            header=True
        )
        
        generate_plots(adata,cell_qc_column,metadata_columns,metadata_columns_original,options.of)


    # Save the updated adata matrix
    # print("Saving data")
    del adata_original.obs['cell_id']
    adata_original.write(
        '{}.h5ad'.format(options.of),
        compression='gzip',
        compression_opts=options.anndata_compression_opts
    )


if __name__ == '__main__':
    main()
